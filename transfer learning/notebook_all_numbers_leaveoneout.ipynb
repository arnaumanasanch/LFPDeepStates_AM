{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "drawn-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(30000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container {width:100% !important;}</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils_models'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m display(HTML(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<style>.container \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mwidth:100\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m !important;}</style>\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mimp\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mutils_models\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mfx\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'utils_models'"
     ]
    }
   ],
   "source": [
    "%autosave 30\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container {width:100% !important;}</style>'))\n",
    "import importlib as imp\n",
    "import utils_models as fx\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-youth",
   "metadata": {},
   "source": [
    "### Training models in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## we do 7 session first !"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Natasha_220107', 'Smith_210213', 'Monica_210703', 'Stanford_211228', 'Skipper_210123', 'Monica_210731', 'Smith_210206'], ['Phoebe_210717']), (['Phoebe_210717', 'Monica_210731', 'Smith_210213', 'Carrie_210108', 'Monica_210703', 'Stanford_211205', 'Natasha_220107'], ['Skipper_210123']), (['Smith_210213', 'Natasha_211211', 'Phoebe_210717', 'Carrie_210108', 'Stanford_211205', 'Skipper_210123', 'Natasha_220107'], ['Monica_210724']), (['Smith_210206', 'Monica_210724', 'Monica_210703', 'Stanford_211205', 'Smith_210213', 'Skipper_210123', 'Carrie_210108'], ['Phoebe_210626']), (['Monica_210724', 'Phoebe_210725', 'Smith_210213', 'Omar_180709', 'Monica_210703', 'Stanford_211228', 'Phoebe_210626'], ['Skipper_210123']), (['Omar_180709', 'Monica_210731', 'Skipper_210123', 'Stanford_211228', 'Natasha_220107', 'Smith_210206', 'Natasha_211211'], ['Phoebe_210620']), (['Phoebe_210620', 'Phoebe_210717', 'Smith_210213', 'Smith_210206', 'Skipper_210123', 'Stanford_211228', 'Natasha_220107'], ['Monica_210703'])]\n"
     ]
    }
   ],
   "source": [
    "original = [\n",
    "    ('Phoebe', '210717', [('Natasha', '220107'), ('Smith', '210213'), ('Monica', '210703'), ('Stanford', '211228'), ('Skipper', '210123'), ('Monica', '210731'), ('Smith', '210206')]),\n",
    "    ('Skipper', '210123', [('Phoebe', '210717'), ('Monica', '210731'), ('Smith', '210213'), ('Carrie', '210108'), ('Monica', '210703'), ('Stanford', '211205'), ('Natasha', '220107')]),\n",
    "    ('Monica', '210724', [('Smith', '210213'), ('Natasha', '211211'), ('Phoebe', '210717'), ('Carrie', '210108'), ('Stanford', '211205'), ('Skipper', '210123'), ('Natasha', '220107')]),\n",
    "    ('Phoebe', '210626', [('Smith', '210206'), ('Monica', '210724'), ('Monica', '210703'), ('Stanford', '211205'), ('Smith', '210213'), ('Skipper', '210123'), ('Carrie', '210108')]),\n",
    "    ('Skipper', '210123', [('Monica', '210724'), ('Phoebe', '210725'), ('Smith', '210213'), ('Omar', '180709'), ('Monica', '210703'), ('Stanford', '211228'), ('Phoebe', '210626')]),\n",
    "    ('Phoebe', '210620', [('Omar', '180709'), ('Monica', '210731'), ('Skipper', '210123'), ('Stanford', '211228'), ('Natasha', '220107'), ('Smith', '210206'), ('Natasha', '211211')]),\n",
    "    ('Monica', '210703', [('Phoebe', '210620'), ('Phoebe', '210717'), ('Smith', '210213'), ('Smith', '210206'), ('Skipper', '210123'), ('Stanford', '211228'), ('Natasha', '220107')])\n",
    "]\n",
    "\n",
    "restructured = [(['_'.join(pair) for pair in session[2]], [session[0] + '_' + session[1]]) for session in original]\n",
    "\n",
    "# Reversing the order for each tuple\n",
    "restructured = [(training, testing) for training, testing in restructured]\n",
    "\n",
    "print(restructured)\n",
    "#[training 1, training2], [testing] aquesta es la estructura. Tota la resta segueix igual.\n",
    "pairs = restructured\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-20T18:47:51.676745Z",
     "end_time": "2023-09-20T18:47:51.679121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dirty-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing data...\n",
      "=================Phoebe=================\n",
      "['Natasha_220107', 'Smith_210213', 'Monica_210703', 'Stanford_211228', 'Skipper_210123', 'Monica_210731', 'Smith_210206'] Phoebe_210717\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(training_ses, testing_ses)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#read data\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m data, states \u001B[38;5;241m=\u001B[39m \u001B[43mfx\u001B[49m\u001B[38;5;241m.\u001B[39mread_data_and_metadata(name, time, best_channel\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     24\u001B[0m training_data\u001B[38;5;241m.\u001B[39mappend(data)\n\u001B[1;32m     25\u001B[0m training_states\u001B[38;5;241m.\u001B[39mextend(states)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'fx' is not defined"
     ]
    }
   ],
   "source": [
    "#loop to go through all the pairs, separating training and testing data\n",
    "for pair in pairs:\n",
    "    try:\n",
    "        del testing_data, training_data, testing_states, training_states\n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "    testing_data = []; training_data = []\n",
    "    testing_states = []; training_states = []\n",
    "    print('Organizing data...')\n",
    "    training_ses = []\n",
    "    testing_ses = []\n",
    "    for session in pair[0]:\n",
    "        training_ses.append(session)\n",
    "    for session in pair[1]:\n",
    "        testing_ses = session\n",
    "    print(f\"================={testing_ses.split('_')[0]}=================\")\n",
    "    for session in training_ses:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        training_data.append(data)\n",
    "        training_states.extend(states)\n",
    "    training_data = np.concatenate(training_data, axis=0)\n",
    "\n",
    "    for session in [testing_ses]:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        testing_data.append(data)\n",
    "        testing_states.extend(states)\n",
    "    testing_data = np.concatenate(testing_data, axis=0)\n",
    "    print('Building Model 1...')\n",
    "    treshold_mod1 = 0.9\n",
    "    name_testing_subject = testing_ses.split('_')[0]\n",
    "    cm1, unknown_counts1 = fx.model1(name_testing_subject + '_transflearning7subs',\n",
    "                                     training_data,\n",
    "                                     training_states,\n",
    "                                     testing_data,\n",
    "                                     testing_states,\n",
    "                                     treshold_mod1,\n",
    "                                     norm=True)  # if normalize_data = False, means that we normalize it across subject BEFORE loop across subjects!!!\n",
    "\n",
    "    print('Building Model 2...')\n",
    "    treshold_mod2 = 0.85\n",
    "    fx.mod2(name_testing_subject + '_transflearning7subs', training_data, training_states, testing_data, testing_states, treshold_mod2, norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## now 5 session !"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Stanford_211228', 'Stanford_211205', 'Phoebe_210725', 'Smith_210213', 'Phoebe_210626'], ['Monica_210724']), (['Skipper_210123', 'Carrie_210108', 'Phoebe_210725', 'Phoebe_210626', 'Smith_210213'], ['Natasha_211211']), (['Natasha_211211', 'Carrie_210108', 'Smith_210213', 'Omar_180709', 'Smith_210206'], ['Monica_210703']), (['Stanford_211228', 'Natasha_211211', 'Carrie_210108', 'Monica_210731', 'Omar_180709'], ['Phoebe_210717']), (['Monica_210724', 'Natasha_220107', 'Stanford_211205', 'Monica_210703', 'Smith_210206'], ['Skipper_210123']), (['Phoebe_210717', 'Phoebe_210626', 'Natasha_211211', 'Smith_210206', 'Phoebe_210620'], ['Skipper_210123']), (['Skipper_210123', 'Smith_210206', 'Monica_210731', 'Phoebe_210620', 'Stanford_211228'], ['Natasha_211211'])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original = [\n",
    "    ('Monica', '210724', [('Stanford', '211228'), ('Stanford', '211205'), ('Phoebe', '210725'), ('Smith', '210213'), ('Phoebe', '210626')]),\n",
    "    ('Natasha', '211211', [('Skipper', '210123'), ('Carrie', '210108'), ('Phoebe', '210725'), ('Phoebe', '210626'), ('Smith', '210213')]),\n",
    "    ('Monica', '210703', [('Natasha', '211211'), ('Carrie', '210108'), ('Smith', '210213'), ('Omar', '180709'), ('Smith', '210206')]),\n",
    "    ('Phoebe', '210717', [('Stanford', '211228'), ('Natasha', '211211'), ('Carrie', '210108'), ('Monica', '210731'), ('Omar', '180709')]),\n",
    "    ('Skipper', '210123', [('Monica', '210724'), ('Natasha', '220107'), ('Stanford', '211205'), ('Monica', '210703'), ('Smith', '210206')]),\n",
    "    ('Skipper', '210123', [('Phoebe', '210717'), ('Phoebe', '210626'), ('Natasha', '211211'), ('Smith', '210206'), ('Phoebe', '210620')]),\n",
    "    ('Natasha', '211211', [('Skipper', '210123'), ('Smith', '210206'), ('Monica', '210731'), ('Phoebe', '210620'), ('Stanford', '211228')])\n",
    "]\n",
    "\n",
    "restructured = [(['_'.join(pair) for pair in session[2]], [session[0] + '_' + session[1]]) for session in original]\n",
    "\n",
    "# Reversing the order for each tuple\n",
    "restructured = [(training, testing) for training, testing in restructured]\n",
    "\n",
    "print(restructured)\n",
    "#[training 1, training2], [testing] aquesta es la estructura. Tota la resta segueix igual.\n",
    "pairs = restructured"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-20T18:49:13.779200Z",
     "end_time": "2023-09-20T18:49:13.783664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#loop to go through all the pairs, separating training and testing data\n",
    "for pair in pairs:\n",
    "    try:\n",
    "        del testing_data, training_data, testing_states, training_states\n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "    testing_data = []; training_data = []\n",
    "    testing_states = []; training_states = []\n",
    "    print('Organizing data...')\n",
    "    training_ses = []\n",
    "    testing_ses = []\n",
    "    for session in pair[0]:\n",
    "        training_ses.append(session)\n",
    "    for session in pair[1]:\n",
    "        testing_ses = session\n",
    "    print(f\"================={testing_ses.split('_')[0]}=================\")\n",
    "    for session in training_ses:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        training_data.append(data)\n",
    "        training_states.extend(states)\n",
    "    training_data = np.concatenate(training_data, axis=0)\n",
    "\n",
    "    for session in [testing_ses]:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        testing_data.append(data)\n",
    "        testing_states.extend(states)\n",
    "    testing_data = np.concatenate(testing_data, axis=0)\n",
    "    print('Building Model 1...')\n",
    "    treshold_mod1 = 0.9\n",
    "    name_testing_subject = testing_ses.split('_')[0]\n",
    "    cm1, unknown_counts1 = fx.model1(name_testing_subject + '_transflearning7subs',\n",
    "                                     training_data,\n",
    "                                     training_states,\n",
    "                                     testing_data,\n",
    "                                     testing_states,\n",
    "                                     treshold_mod1,\n",
    "                                     norm=True)  # if normalize_data = False, means that we normalize it across subject BEFORE loop across subjects!!!\n",
    "\n",
    "    print('Building Model 2...')\n",
    "    treshold_mod2 = 0.85\n",
    "    fx.mod2(name_testing_subject + '_transflearning5subs', training_data, training_states, testing_data, testing_states, treshold_mod2, norm=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## now 2 session !"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#[training 1, training2], [testing] aquesta es la estructura. Tota la resta segueix igual.\n",
    "original = [\n",
    "    ('Phoebe', '210626', [('Monica', '210724'),('Natasha', '211211')]),\n",
    "    ('Skipper', '210123', [('Phoebe', '210626'),('Smith', '210213')]),\n",
    "    ('Phoebe', '210725', [('Natasha', '211211'),('Carrie', '210108')]),\n",
    "    ('Natasha', '220107', [('Phoebe', '210626'),('Phoebe', '210620')]),\n",
    "    ('Monica', '210724', [('Phoebe', '210717'),('Smith', '210213')]),\n",
    "    ('Monica', '210731', [('Smith', '210213'),('Phoebe', '210725')]),\n",
    "    ('Phoebe', '210717', [('Carrie', '210108'),('Monica', '210703')])\n",
    "]\n",
    "\n",
    "restructured = [(['_'.join(pair) for pair in session[2]], [session[0] + '_' + session[1]]) for session in original]\n",
    "\n",
    "# Reversing the order for each tuple\n",
    "restructured = [(training, testing) for training, testing in restructured]\n",
    "\n",
    "print(restructured)\n",
    "pairs = restructured"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#loop to go through all the pairs, separating training and testing data\n",
    "for pair in pairs:\n",
    "    try:\n",
    "        del testing_data, training_data, testing_states, training_states\n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "    testing_data = []; training_data = []\n",
    "    testing_states = []; training_states = []\n",
    "    print('Organizing data...')\n",
    "    training_ses = []\n",
    "    testing_ses = []\n",
    "    for session in pair[0]:\n",
    "        training_ses.append(session)\n",
    "    for session in pair[1]:\n",
    "        testing_ses = session\n",
    "    print(f\"================={testing_ses.split('_')[0]}=================\")\n",
    "    for session in training_ses:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        training_data.append(data)\n",
    "        training_states.extend(states)\n",
    "    training_data = np.concatenate(training_data, axis=0)\n",
    "\n",
    "    for session in [testing_ses]:\n",
    "        name = session.split('_')[0]\n",
    "        time = session.split('_')[1]\n",
    "        #read data\n",
    "        data, states = fx.read_data_and_metadata(name, time, best_channel=True)\n",
    "        testing_data.append(data)\n",
    "        testing_states.extend(states)\n",
    "    testing_data = np.concatenate(testing_data, axis=0)\n",
    "    print('Building Model 1...')\n",
    "    treshold_mod1 = 0.9\n",
    "    name_testing_subject = testing_ses.split('_')[0]\n",
    "    cm1, unknown_counts1 = fx.model1(name_testing_subject + '_transflearning7subs',\n",
    "                                     training_data,\n",
    "                                     training_states,\n",
    "                                     testing_data,\n",
    "                                     testing_states,\n",
    "                                     treshold_mod1,\n",
    "                                     norm=True)  # if normalize_data = False, means that we normalize it across subject BEFORE loop across subjects!!!\n",
    "\n",
    "    print('Building Model 2...')\n",
    "    treshold_mod2 = 0.85\n",
    "    fx.mod2(name_testing_subject + '_transflearning2subs', training_data, training_states, testing_data, testing_states, treshold_mod2, norm=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
